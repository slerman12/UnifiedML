# Copyright (c) AGI.__init__. All Rights Reserved.
#
# This source code is licensed under the MIT license found in the
# MIT_LICENSE file in the root directory of this source tree.
import math
from typing import List, Tuple, Optional, Dict

import torch
import torch.nn as nn
import torch.nn.functional as F

from torchvision.transforms import transforms, InterpolationMode, functional as vF


class RandomShiftsAug(nn.Module):
    def __init__(self, pad):
        super().__init__()
        self.pad = pad

    def forward(self, x):
        # Operates on last 3 dims of x, preserves leading dims
        shape = x.shape
        x = x.view(-1, *shape[-3:])
        n, c, h, w = x.size()
        assert h == w
        padding = tuple([self.pad] * 4)
        x = F.pad(x, padding, 'replicate')
        eps = 1.0 / (h + 2 * self.pad)
        arange = torch.linspace(-1.0 + eps,
                                1.0 - eps,
                                h + 2 * self.pad,
                                device=x.device,
                                dtype=x.dtype)[:h]
        arange = arange.unsqueeze(0).repeat(h, 1).unsqueeze(2)
        base_grid = torch.cat([arange, arange.transpose(1, 0)], dim=2)
        base_grid = base_grid.unsqueeze(0).repeat(n, 1, 1, 1)

        shift = torch.randint(0,
                              2 * self.pad + 1,
                              size=(n, 1, 1, 2),
                              device=x.device,
                              dtype=x.dtype)
        shift *= 2.0 / (h + 2 * self.pad)

        grid = base_grid + shift
        output = F.grid_sample(x,
                               grid,
                               padding_mode='zeros',
                               align_corners=False)
        return output.view(*shape[:-3], *output.shape[-3:])


class IntensityAug(nn.Module):
    def __init__(self, scale=0.1):
        super().__init__()
        self.scale = scale

    def forward(self, x):
        noise = 1.0 + (self.scale * torch.randn(
            (x.shape[0], 1, 1, 1), device=x.device).clamp_(-2.0, 2.0))
        return x * noise


class ComposeAugs(nn.Module):
    def __init__(self, augs):
        super().__init__()
        self.transform = transforms.Compose([getattr(transforms, aug)(**augs[aug]) if hasattr(transforms, aug) else
                                             globals()[aug](**augs[aug]) for aug in augs])

    def forward(self, x):
        return self.transform(x)


# def _apply_op(
#         img: torch.Tensor, op_name: str, magnitude: float, interpolation: InterpolationMode, fill: Optional[List[float]]
# ):
#     img = img.to(torch.uint8)
#     if op_name == "ShearX":
#         # magnitude should be arctan(magnitude)
#         # official autoaug: (1, level, 0, 0, 1, 0)
#         # https://github.com/tensorflow/models/blob/dd02069717128186b88afa8d857ce57d17957f03/research/autoaugment/augmentation_transforms.py#L290
#         # compared to
#         # torchvision:      (1, tan(level), 0, 0, 1, 0)
#         # https://github.com/pytorch/vision/blob/0c2373d0bba3499e95776e7936e207d8a1676e65/torchvision/transforms/functional.py#L976
#         img = vF.affine(
#             img,
#             angle=0.0,
#             translate=[0, 0],
#             scale=1.0,
#             shear=[math.degrees(math.atan(magnitude)), 0.0],
#             interpolation=interpolation,
#             fill=fill,
#         )
#     elif op_name == "ShearY":
#         # magnitude should be arctan(magnitude)
#         # See above
#         img = vF.affine(
#             img,
#             angle=0.0,
#             translate=[0, 0],
#             scale=1.0,
#             shear=[0.0, math.degrees(math.atan(magnitude))],
#             interpolation=interpolation,
#             fill=fill,
#         )
#     elif op_name == "TranslateX":
#         img = vF.affine(
#             img,
#             angle=0.0,
#             translate=[int(magnitude), 0],
#             scale=1.0,
#             interpolation=interpolation,
#             shear=[0.0, 0.0],
#             fill=fill,
#         )
#     elif op_name == "TranslateY":
#         img = vF.affine(
#             img,
#             angle=0.0,
#             translate=[0, int(magnitude)],
#             scale=1.0,
#             interpolation=interpolation,
#             shear=[0.0, 0.0],
#             fill=fill,
#         )
#     elif op_name == "Rotate":
#         img = vF.rotate(img, magnitude, interpolation=interpolation, fill=fill)
#     elif op_name == "Brightness":
#         img = vF.adjust_brightness(img, 1.0 + magnitude)
#     elif op_name == "Color":
#         img = vF.adjust_saturation(img, 1.0 + magnitude)
#     elif op_name == "Contrast":
#         img = vF.adjust_contrast(img, 1.0 + magnitude)
#     elif op_name == "Sharpness":
#         img = vF.adjust_sharpness(img, 1.0 + magnitude)
#     elif op_name == "Posterize":
#         img = vF.posterize(img, int(magnitude))
#     elif op_name == "Solarize":
#         img = vF.solarize(img, magnitude)
#     elif op_name == "AutoContrast":
#         img = vF.autocontrast(img)
#     elif op_name == "Equalize":
#         img = vF.equalize(img)
#     elif op_name == "Invert":
#         img = vF.invert(img)
#     elif op_name == "Identity":
#         pass
#     else:
#         raise ValueError(f"The provided operator {op_name} is not recognized.")
#     return img
#
#
# class RandAugment(torch.nn.Module):
#     r"""RandAugment data augmentation method based on
#     `"RandAugment: Practical automated data augmentation with a reduced search space"
#     <https://arxiv.org/abs/1909.13719>`_.
#     If the image is torch Tensor, it should be of type torch.uint8, and it is expected
#     to have [..., 1 or 3, H, W] shape, where ... means an arbitrary number of leading dimensions.
#     If img is PIL Image, it is expected to be in mode "L" or "RGB".
#
#     Args:
#         num_ops (int): Number of augmentation transformations to apply sequentially.
#         magnitude (int): Magnitude for all the transformations.
#         num_magnitude_bins (int): The number of different magnitude values.
#         interpolation (InterpolationMode): Desired interpolation enum defined by
#             :class:`torchvision.transforms.InterpolationMode`. Default is ``InterpolationMode.NEAREST``.
#             If input is Tensor, only ``InterpolationMode.NEAREST``, ``InterpolationMode.BILINEAR`` are supported.
#         fill (sequence or number, optional): Pixel fill value for the area outside the transformed
#             image. If given a number, the value is used for all bands respectively.
#     """
#
#     def __init__(
#             self,
#             num_ops: int = 2,
#             magnitude: int = 9,
#             num_magnitude_bins: int = 31,
#             interpolation: InterpolationMode = InterpolationMode.NEAREST,
#             fill: Optional[List[float]] = None,
#     ) -> None:
#         super().__init__()
#         self.num_ops = num_ops
#         self.magnitude = magnitude
#         self.num_magnitude_bins = num_magnitude_bins
#         self.interpolation = interpolation
#         self.fill = fill
#
#     def _augmentation_space(self, num_bins: int, image_size: Tuple[int, int]) -> Dict[str, Tuple[torch.Tensor, bool]]:
#         return {
#             # op_name: (magnitudes, signed)
#             "Identity": (torch.tensor(0.0), False),
#             "ShearX": (torch.linspace(0.0, 0.3, num_bins), True),
#             "ShearY": (torch.linspace(0.0, 0.3, num_bins), True),
#             "TranslateX": (torch.linspace(0.0, 150.0 / 331.0 * image_size[1], num_bins), True),
#             "TranslateY": (torch.linspace(0.0, 150.0 / 331.0 * image_size[0], num_bins), True),
#             "Rotate": (torch.linspace(0.0, 30.0, num_bins), True),
#             "Brightness": (torch.linspace(0.0, 0.9, num_bins), True),
#             "Color": (torch.linspace(0.0, 0.9, num_bins), True),
#             "Contrast": (torch.linspace(0.0, 0.9, num_bins), True),
#             "Sharpness": (torch.linspace(0.0, 0.9, num_bins), True),
#             "Posterize": (8 - (torch.arange(num_bins) / ((num_bins - 1) / 4)).round().int(), False),
#             "Solarize": (torch.linspace(255.0, 0.0, num_bins), False),
#             "AutoContrast": (torch.tensor(0.0), False),
#             "Equalize": (torch.tensor(0.0), False),
#         }
#
#     def forward(self, img: torch.Tensor) -> torch.Tensor:
#         """
#             img (PIL Image or Tensor): Image to be transformed.
#
#         Returns:
#             PIL Image or Tensor: Transformed image.
#         """
#         fill = self.fill
#         channels, height, width = img.shape[-3:]
#         if isinstance(img, torch.Tensor):
#             if isinstance(fill, (int, float)):
#                 fill = [float(fill)] * channels
#             elif fill is not None:
#                 fill = [float(f) for f in fill]
#
#         op_meta = self._augmentation_space(self.num_magnitude_bins, (height, width))
#         for _ in range(self.num_ops):
#             op_index = int(torch.randint(len(op_meta), (1,)).item())
#             op_name = list(op_meta.keys())[op_index]
#             magnitudes, signed = op_meta[op_name]
#             magnitude = float(magnitudes[self.magnitude].item()) if magnitudes.ndim > 0 else 0.0
#             if signed and torch.randint(2, (1,)):
#                 magnitude *= -1.0
#             img = _apply_op(img, op_name, magnitude, interpolation=self.interpolation, fill=fill)
#
#         return img
#
#     def __repr__(self) -> str:
#         s = (
#             f"{self.__class__.__name__}("
#             f"num_ops={self.num_ops}"
#             f", magnitude={self.magnitude}"
#             f", num_magnitude_bins={self.num_magnitude_bins}"
#             f", interpolation={self.interpolation}"
#             f", fill={self.fill}"
#             f")"
#         )
#         return s

import random

import PIL, PIL.ImageOps, PIL.ImageEnhance, PIL.ImageDraw
import numpy as np
import torch
from PIL import Image


def ShearX(img, v):  # [-0.3, 0.3]
    assert -0.3 <= v <= 0.3
    if random.random() > 0.5:
        v = -v
    return img.transform(img.size, PIL.Image.AFFINE, (1, v, 0, 0, 1, 0))


def ShearY(img, v):  # [-0.3, 0.3]
    assert -0.3 <= v <= 0.3
    if random.random() > 0.5:
        v = -v
    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, v, 1, 0))


def TranslateX(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]
    assert -0.45 <= v <= 0.45
    if random.random() > 0.5:
        v = -v
    v = v * img.size[0]
    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, v, 0, 1, 0))


def TranslateXabs(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]
    assert 0 <= v
    if random.random() > 0.5:
        v = -v
    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, v, 0, 1, 0))


def TranslateY(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]
    assert -0.45 <= v <= 0.45
    if random.random() > 0.5:
        v = -v
    v = v * img.size[1]
    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, 0, 1, v))


def TranslateYabs(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]
    assert 0 <= v
    if random.random() > 0.5:
        v = -v
    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, 0, 1, v))


def Rotate(img, v):  # [-30, 30]
    assert -30 <= v <= 30
    if random.random() > 0.5:
        v = -v
    return img.rotate(v)


def AutoContrast(img, _):
    return PIL.ImageOps.autocontrast(img)


def Invert(img, _):
    return vF.invert(img)


def Equalize(img, _):
    return PIL.ImageOps.equalize(img)


def Flip(img, _):  # not from the paper
    return PIL.ImageOps.mirror(img)


def Solarize(img, v):  # [0, 256]
    assert 0 <= v <= 256
    return PIL.ImageOps.solarize(img, v)


def SolarizeAdd(img, addition=0, threshold=128):
    img_np = np.array(img).astype(np.int)
    img_np = img_np + addition
    img_np = np.clip(img_np, 0, 255)
    img_np = img_np.astype(np.uint8)
    img = Image.fromarray(img_np)
    return PIL.ImageOps.solarize(img, threshold)


def Posterize(img, v):  # [4, 8]
    v = int(v)
    v = max(1, v)
    return PIL.ImageOps.posterize(img, v)


def Contrast(img, v):  # [0.1,1.9]
    assert 0.1 <= v <= 1.9
    return PIL.ImageEnhance.Contrast(img).enhance(v)


def Color(img, v):  # [0.1,1.9]
    assert 0.1 <= v <= 1.9
    return PIL.ImageEnhance.Color(img).enhance(v)


def Brightness(img, v):  # [0.1,1.9]
    assert 0.1 <= v <= 1.9
    return PIL.ImageEnhance.Brightness(img).enhance(v)


def Sharpness(img, v):  # [0.1,1.9]
    assert 0.1 <= v <= 1.9
    return PIL.ImageEnhance.Sharpness(img).enhance(v)


def Cutout(img, v):  # [0, 60] => percentage: [0, 0.2]
    assert 0.0 <= v <= 0.2
    if v <= 0.:
        return img

    v = v * img.size[0]
    return CutoutAbs(img, v)


def CutoutAbs(img, v):  # [0, 60] => percentage: [0, 0.2]
    # assert 0 <= v <= 20
    if v < 0:
        return img
    w, h = img.size
    x0 = np.random.uniform(w)
    y0 = np.random.uniform(h)

    x0 = int(max(0, x0 - v / 2.))
    y0 = int(max(0, y0 - v / 2.))
    x1 = min(w, x0 + v)
    y1 = min(h, y0 + v)

    xy = (x0, y0, x1, y1)
    color = (125, 123, 114)
    # color = (0, 0, 0)
    img = img.copy()
    PIL.ImageDraw.Draw(img).rectangle(xy, color)
    return img


def SamplePairing(imgs):  # [0, 0.4]
    def f(img1, v):
        i = np.random.choice(len(imgs))
        img2 = PIL.Image.fromarray(imgs[i])
        return PIL.Image.blend(img1, img2, v)

    return f


def Identity(img, v):
    return img


def augment_list():  # 16 oeprations and their ranges
    # https://github.com/google-research/uda/blob/master/image/randaugment/policies.py#L57
    # l = [
    #     (Identity, 0., 1.0),
    #     (ShearX, 0., 0.3),  # 0
    #     (ShearY, 0., 0.3),  # 1
    #     (TranslateX, 0., 0.33),  # 2
    #     (TranslateY, 0., 0.33),  # 3
    #     (Rotate, 0, 30),  # 4
    #     (AutoContrast, 0, 1),  # 5
    #     (Invert, 0, 1),  # 6
    #     (Equalize, 0, 1),  # 7
    #     (Solarize, 0, 110),  # 8
    #     (Posterize, 4, 8),  # 9
    #     # (Contrast, 0.1, 1.9),  # 10
    #     (Color, 0.1, 1.9),  # 11
    #     (Brightness, 0.1, 1.9),  # 12
    #     (Sharpness, 0.1, 1.9),  # 13
    #     # (Cutout, 0, 0.2),  # 14
    #     # (SamplePairing(imgs), 0, 0.4),  # 15
    # ]

    # https://github.com/tensorflow/tpu/blob/8462d083dd89489a79e3200bcc8d4063bf362186/models/official/efficientnet/autoaugment.py#L505
    l = [
        (AutoContrast, 0, 1),
        (Equalize, 0, 1),
        (Invert, 0, 1),
        (Rotate, 0, 30),
        (Posterize, 0, 4),
        (Solarize, 0, 256),
        (SolarizeAdd, 0, 110),
        (Color, 0.1, 1.9),
        (Contrast, 0.1, 1.9),
        (Brightness, 0.1, 1.9),
        (Sharpness, 0.1, 1.9),
        (ShearX, 0., 0.3),
        (ShearY, 0., 0.3),
        (CutoutAbs, 0, 40),
        (TranslateXabs, 0., 100),
        (TranslateYabs, 0., 100),
    ]

    return l


class Lighting(object):
    """Lighting noise(AlexNet - style PCA - based noise)"""

    def __init__(self, alphastd, eigval, eigvec):
        self.alphastd = alphastd
        self.eigval = torch.Tensor(eigval)
        self.eigvec = torch.Tensor(eigvec)

    def __call__(self, img):
        if self.alphastd == 0:
            return img

        alpha = img.new().resize_(3).normal_(0, self.alphastd)
        rgb = self.eigvec.type_as(img).clone() \
            .mul(alpha.view(1, 3).expand(3, 3)) \
            .mul(self.eigval.view(1, 3).expand(3, 3)) \
            .sum(1).squeeze()

        return img.add(rgb.view(3, 1, 1).expand_as(img))


class CutoutDefault(object):
    """
    Reference : https://github.com/quark0/darts/blob/master/cnn/utils.py
    """
    def __init__(self, length):
        self.length = length

    def __call__(self, img):
        h, w = img.size(1), img.size(2)
        mask = np.ones((h, w), np.float32)
        y = np.random.randint(h)
        x = np.random.randint(w)

        y1 = np.clip(y - self.length // 2, 0, h)
        y2 = np.clip(y + self.length // 2, 0, h)
        x1 = np.clip(x - self.length // 2, 0, w)
        x2 = np.clip(x + self.length // 2, 0, w)

        mask[y1: y2, x1: x2] = 0.
        mask = torch.from_numpy(mask)
        mask = mask.expand_as(img)
        img *= mask
        return img


class RandAugment:
    def __init__(self, n, magnitude):
        self.n = n
        self.m = magnitude      # [0, 30]
        self.augment_list = augment_list()

    def __call__(self, img):
        ops = random.choices(self.augment_list, k=self.n)
        for op, minval, maxval in ops:
            val = (float(self.m) / 30) * float(maxval - minval) + minval
            img = op(img, val)

        return img